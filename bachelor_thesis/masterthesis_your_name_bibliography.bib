@article{JMLR:v23:21-0524,
  author  = {T. Tony Cai and Rong Ma},
  title   = {Theoretical Foundations of t-SNE for Visualizing High-Dimensional Clustered Data},
  journal = {Journal of Machine Learning Research},
  year    = {2022},
  volume  = {23},
  number  = {301},
  pages   = {1--54},
  url     = {http://jmlr.org/papers/v23/21-0524.html}
}

@article{LinStei22,
author = {Linderman, George C. and Steinerberger, Stefan},
title = {Dimensionality Reduction via Dynamical Systems: The Case of t-SNE},
journal = {SIAM Review},
volume = {64},
number = {1},
pages = {153-178},
year = {2022},
doi = {10.1137/21M1446769},
URL = { 
        https://doi.org/10.1137/21M1446769
},
eprint = { 
        https://doi.org/10.1137/21M1446769
}
,
    abstract = { t-distributed stochastic neighborhood embedding (t-SNE), a clustering and visualization method proposed by van der Maaten and Hinton in 2008, has rapidly become a standard tool in the natural sciences. Despite its overwhelming success, it has a distinct lack of mathematical foundations and the inner workings of the algorithm are not well understood. The purpose of this paper is to prove that t-SNE is able to recover well-separated clusters. As a by-product, the proof suggests that t-SNE is merely one of many possible algorithms of a large family of methods generated by dynamical systems---this perspective suggests new questions and problems, some of which we discuss. }
}

@article{belkina19,
	abstract = {Accurate and comprehensive extraction of information from high-dimensional single cell datasets necessitates faithful visualizations to assess biological populations. A state-of-the-art algorithm for non-linear dimension reduction, t-SNE, requires multiple heuristics and fails to produce clear representations of datasets when millions of cells are projected. We develop opt-SNE, an automated toolkit for t-SNE parameter selection that utilizes Kullback-Leibler divergence evaluation in real time to tailor the early exaggeration and overall number of gradient descent iterations in a dataset-specific manner. The precise calibration of early exaggeration together with opt-SNE adjustment of gradient descent learning rate dramatically improves computation time and enables high-quality visualization of large cytometry and transcriptomics datasets, overcoming limitations of analysis tools with hard-coded parameters that often produce poorly resolved or misleading maps of fluorescent and mass cytometry data. In summary, opt-SNE enables superior data resolution in t-SNE space and thereby more accurate data interpretation.},
	author = {Belkina, Anna C. and Ciccolella, Christopher O. and Anno, Rina and Halpert, Richard and Spidlen, Josef and Snyder-Cappione, Jennifer E.},
	date = {2019/11/28},
	date-added = {2025-01-29 14:46:19 +0100},
	date-modified = {2025-01-29 14:46:19 +0100},
	doi = {10.1038/s41467-019-13055-y},
	id = {Belkina2019},
	isbn = {2041-1723},
	journal = {Nature Communications},
	number = {1},
	pages = {5415},
	title = {Automated optimized parameters for T-distributed stochastic neighbor embedding improve visualization and analysis of large datasets},
	url = {https://doi.org/10.1038/s41467-019-13055-y},
	volume = {10},
	year = {2019},
	bdsk-url-1 = {https://doi.org/10.1038/s41467-019-13055-y}}


@article{kobak21,
	author = {Kobak, Dmitry and Linderman, George C.},
	date = {2021/02/01},
	date-added = {2025-01-29 14:37:35 +0100},
	date-modified = {2025-01-29 14:38:28 +0100},
	doi = {10.1038/s41587-020-00809-z},
	id = {Kobak2021},
	isbn = {1546-1696},
	journal = {Nature Biotechnology},
	number = {2},
	pages = {156--157},
	title = {Initialization is critical for preserving global data structure in both t-SNE and UMAP},
	url = {https://doi.org/10.1038/s41587-020-00809-z},
	volume = {39},
	year = {2021},
	bdsk-url-1 = {https://doi.org/10.1038/s41587-020-00809-z}}




