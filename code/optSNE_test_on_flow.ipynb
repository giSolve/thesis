{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Various Tests of opt-SNE on flow data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will investigate: \n",
    "- 1NN accuracy and KLD values of embeddings \n",
    "- across \"bh\" vs \"fft\" \n",
    "- random vs pca init \n",
    "- embeddings with or without opt-SNE automated stopping "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# imports \n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import flowkit as fk \n",
    "from openTSNE import TSNE\n",
    "\n",
    "# Pre-processing data \n",
    "sample = fk.Sample('data/flow18_annotated.fcs', sample_id='flow18', channel_labels=('Parameter_1', 'Parameter_10', 'Parameter_11', 'Parameter_12', 'Parameter_13', 'Parameter_14', 'Parameter_15', 'Parameter_16', 'Parameter_17', 'Parameter_18', 'Parameter_19', 'Parameter_2', 'Parameter_20', 'Parameter_21', 'Parameter_22', 'Parameter_23', 'Parameter_24', 'Parameter_3', 'Parameter_4', 'Parameter_5', 'Parameter_6', 'Parameter_7', 'Parameter_8', 'Parameter_9', 'SampleID', 'class'))\n",
    "df_events = sample.as_dataframe(source=\"raw\")\n",
    "\n",
    "# only use selected columns \n",
    "selected_columns = [\n",
    "    'Parameter_10', 'Parameter_11', 'Parameter_12', \n",
    "    'Parameter_13', 'Parameter_15', 'Parameter_18', 'Parameter_20', \n",
    "    'Parameter_21', 'Parameter_23', 'Parameter_8', 'Parameter_9', 'class'\n",
    "]\n",
    "\n",
    "df_filtered = df_events[selected_columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KLD Monitoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openTSNE import callbacks\n",
    "buffer_ee = 15\n",
    "switch_buffer = 2 \n",
    "\n",
    "class KLDRCMonitorEE(callbacks.Callback):\n",
    "    def __init__(self, record_every=3):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "            record_every (int): Check KL divergence every this many iterations.\n",
    "            buffer_ee (int): Minimum iterations before monitoring KL divergence.\n",
    "            switch_buffer (int): Extra iterations to confirm EE phase exit.\n",
    "        \"\"\"\n",
    "        self.record_every = record_every  # Equivalent to `auto_iter_pollrate_ee = 3`\n",
    "        \n",
    "        self.kl_divergences = []\n",
    "        self.last_error = None\n",
    "        self.last_rel_change = None\n",
    "        self.switch_buffer_count = switch_buffer  # Tracks remaining iterations before exiting EE\n",
    "\n",
    "    def __call__(self, iteration, error, embedding):\n",
    "        \"\"\"\n",
    "        Monitors KL divergence and determines when to stop Early Exaggeration.\n",
    "        Returns True if EE should stop.\n",
    "        \"\"\"\n",
    "        # Only check every `record_every` iterations\n",
    "        if iteration % self.record_every == 0:\n",
    "            self.kl_divergences.append((iteration, error))\n",
    "\n",
    "            if self.last_error is not None:\n",
    "                # Compute relative change: (prev_error - current_error) / prev_error\n",
    "                rel_change = 100 * (self.last_error - error) / self.last_error  \n",
    "\n",
    "                print(f\"Iteration {iteration}: KL Divergence = {error:.4f}, Relative Change = {rel_change:.4f}%\")\n",
    "\n",
    "                # Start checking only after `buffer_ee` iterations\n",
    "                if iteration > buffer_ee:\n",
    "                    if self.last_rel_change is not None and rel_change < self.last_rel_change:\n",
    "                        # If relative change decreases, start the switch buffer countdown\n",
    "                        if self.switch_buffer_count < 1:\n",
    "                            print(\"Relative change has consistently decreased. Stopping Early Exaggeration.\")\n",
    "                            print(f\"EE Iteration stopped at {iteration}\")\n",
    "                            return True  # Signal to stop EE phase\n",
    "                        self.switch_buffer_count -= 1\n",
    "                    else:\n",
    "                        # Reset switch buffer if relative change increases again\n",
    "                        self.switch_buffer_count = switch_buffer\n",
    "\n",
    "                self.last_rel_change = rel_change\n",
    "\n",
    "            # Update last error for the next iteration\n",
    "            self.last_error = error\n",
    "\n",
    "        EE_iteration_stopped = iteration \n",
    "        return False  # Continue EE phase if conditions are not met\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KLDRCMonitorNoOpt(callbacks.Callback):\n",
    "    def __init__(self, record_every=5):\n",
    "     \n",
    "        self.record_every = record_every  # Equivalent to `auto_iter_pollrate_ee = 3`\n",
    "        self.kl_divergences = []\n",
    "\n",
    "    def __call__(self, iteration, error, embedding):\n",
    "        \"\"\"\n",
    "        Monitors KL divergence. \n",
    "        \"\"\"\n",
    "        # Only check every `record_every` iterations\n",
    "        if iteration % self.record_every == 0:\n",
    "            self.kl_divergences.append((iteration, error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "buffer_run = 150 \n",
    "auto_iter_end = 100 \n",
    "\n",
    "class KLDRCMonitorRun(callbacks.Callback):\n",
    "    def __init__(self, record_every=5):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "            record_every (int): Check KL divergence every this many iterations.\n",
    "            buffer_run (int): Minimum iterations after EE before monitoring for stopping.\n",
    "            auto_iter_end (float): Threshold for stopping, lower values stop earlier.\n",
    "        \"\"\"\n",
    "        self.record_every = record_every  # Equivalent to `auto_iter_pollrate_run = 5`\n",
    "        # self.buffer_run = buffer_run  # Equivalent to `auto_iter_buffer_run = 15`\n",
    "        # self.auto_iter_end = auto_iter_end  # Used for stopping condition\n",
    "\n",
    "        self.kl_divergences = []\n",
    "        self.last_error = None\n",
    "\n",
    "    def __call__(self, iteration, error, embedding):\n",
    "        \"\"\"\n",
    "        Monitors KL divergence and determines when to stop the full t-SNE run.\n",
    "        Returns True if the run should stop.\n",
    "        \"\"\"\n",
    "        # Only check KL divergence every `record_every` iterations\n",
    "        if iteration % self.record_every == 0:\n",
    "            self.kl_divergences.append((iteration, error))\n",
    "\n",
    "            if self.last_error is not None:\n",
    "                # Compute absolute error difference\n",
    "                error_diff = abs(self.last_error - error)\n",
    "\n",
    "                print(f\"Iteration {iteration}: KL Divergence = {error:.4f}, Error Diff = {error_diff:.6f}\")\n",
    "\n",
    "                # Start monitoring only after `buffer_run` iterations have passed\n",
    "                if iteration > buffer_run:\n",
    "                    # Stopping condition from C++: abs(error_diff)/pollrate < error/auto_iter_end\n",
    "                    if (error_diff / self.record_every) < (error / auto_iter_end):\n",
    "                        print(\"KL divergence change is below threshold. Stopping optimization.\")\n",
    "                        print(f\"Run iteration stopped at {iteration}\")\n",
    "                        return True  # Signal to stop t-SNE run\n",
    "\n",
    "            # Update last error\n",
    "            self.last_error = error\n",
    "\n",
    "        return False  # Continue t-SNE run\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1NN Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "def compute_1nn_accuracy(Y, labels):\n",
    "    \"\"\"\n",
    "    Computes the 1-Nearest Neighbor (1NN) accuracy of the t-SNE embedding.\n",
    "\n",
    "    Parameters:\n",
    "    - Y (numpy array): t-SNE embedding of shape (N, no_dims)\n",
    "    - labels (numpy array): Ground truth labels of shape (N,)\n",
    "\n",
    "    Returns:\n",
    "    - accuracy (float): 1NN classification accuracy\n",
    "    \"\"\"\n",
    "    N = Y.shape[0]  # Number of data points\n",
    "\n",
    "    # Use Nearest Neighbors to find the closest point\n",
    "    nn = NearestNeighbors(n_neighbors=2, metric='euclidean')  # Find 2 nearest (1st is itself)\n",
    "    nn.fit(Y)\n",
    "    distances, indices = nn.kneighbors(Y)  # Get nearest neighbor indices\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    # The 1NN prediction is the label of the nearest neighbor (not itself)\n",
    "    nearest_neighbor_indices = indices[:, 1]  # Take the second closest (first is itself)\n",
    "    predicted_labels = labels[nearest_neighbor_indices]\n",
    "\n",
    "    # Compute accuracy\n",
    "    accuracy = np.mean(predicted_labels == labels)  # Check how many match\n",
    "\n",
    "    return accuracy\n",
    "\n",
    "# Example Usage\n",
    "# Y: Your t-SNE embedding of shape (N, 2) or (N, 3)\n",
    "# labels: Ground truth labels of shape (N,)\n",
    "# accuracy = compute_1nn_accuracy(Y, labels)\n",
    "# print(f\"1NN Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_embedding(embedding, labels, data_percentage, neg_grad_method, init, learning_rate):     \n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.scatter(\n",
    "        embedding[:, 0], \n",
    "        embedding[:, 1], \n",
    "        c=labels, \n",
    "        cmap=plt.colormaps.get_cmap('Paired'), \n",
    "        s=10, \n",
    "        alpha=0.4\n",
    "    )\n",
    "    plt.title(f\"opt-SNE on flow18, {100*data_percentage}% of dataset, {neg_grad_method}, {init} initialization, {learning_rate} learning rate\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wissrech",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
